# æœ€ç»ˆä¿®å¤æ–¹æ¡ˆæ€»ç»“

## ğŸ¯ é—®é¢˜æ ¹æºå‘ç°

ç»è¿‡æ·±å…¥åˆ†æé”™è¯¯å †æ ˆå’Œæºç ï¼Œå‘ç°äº†**çœŸæ­£çš„é—®é¢˜**ï¼š

### Qwen3 ä½¿ç”¨çš„æ˜¯ MCoreï¼ˆParallel Coreï¼‰æ¶æ„

ä»é”™è¯¯å †æ ˆå¯ä»¥çœ‹åˆ°è°ƒç”¨è·¯å¾„ï¼š
```
modeling_qwen3_infer.py
â†’ parallel_core/inference/base_models/gpt/gpt_model.py
â†’ parallel_core/inference/transformer/transformer_layer.py
â†’ parallel_core/inference/transformer/attention.py
â†’ parallel_core/inference/base_models/common/embeddings/rotary_pos_embedding.py
```

è¿™è¯´æ˜ Qwen3 ä½¿ç”¨çš„æ˜¯ **MCore æ¶æ„**ï¼Œè€Œä¸æ˜¯ Legacy æ¶æ„ï¼

## ğŸ” é”™è¯¯åŸå› åˆ†æ

### ä¸ºä»€ä¹ˆ position_ids ä¸€ç›´æ˜¯ Noneï¼Ÿ

```python
# âŒ é”™è¯¯ï¼šå¯¹ MCore æ¨¡å‹è°ƒç”¨ Legacy æ¥å£
model.infer(
    input_ids=input_ids_np,
    valid_length_each_example=valid_length_each_example,
    generation_config=gen_config,
    position_ids=position_ids,  # ä¼ é€’äº†ï¼Œä½†æ²¡ç”¨ï¼
)
```

**é—®é¢˜æ‰€åœ¨**ï¼š
1. è°ƒç”¨çš„æ˜¯ Legacy çš„ `infer()` æ¥å£
2. Legacy æ¥å£å†…éƒ¨è°ƒç”¨ `prepare_inputs_for_generation()`
3. ä½† MCore æ¨¡å‹éœ€è¦è°ƒç”¨ `prepare_inputs_for_generation_mcore()`
4. position_ids åœ¨ä¸¤ä¸ªè·¯å¾„ä¸­çš„å¤„ç†æ–¹å¼å®Œå…¨ä¸åŒï¼

### MCore vs Legacy çš„å…³é”®åŒºåˆ«

#### Legacy æ¶æ„ï¼ˆæ—§ç‰ˆï¼‰
```python
def prepare_inputs_for_generation(self, input_ids, **kwargs):
    model_inputs = {"input_ids": Tensor.from_numpy(input_ids.astype(np.int32))}
    # position_ids éœ€è¦æ˜¾å¼ä» kwargs ä¸­è·å–å¹¶ä¼ é€’
    return model_inputs
```

#### MCore æ¶æ„ï¼ˆæ–°ç‰ˆï¼ŒQwen3ï¼‰
```python
def prepare_inputs_for_generation_mcore(self, input_ids, **model_kwargs):
    # ä» model_kwargs è·å– position_ids
    positions = model_kwargs.get("position_ids", None)
    
    # å¦‚æœæ²¡æœ‰ï¼Œè‡ªåŠ¨ç”Ÿæˆï¼
    if positions is None:
        positions = np.zeros_like(input_ids, dtype=np.int32)
        start = 0
        for i in range(seq_lens.size):
            positions[start:start + q_seq_lens[i]] = np.arange(context_lens[i], seq_lens[i])
            start += q_seq_lens[i]
    
    # è½¬æ¢ä¸º Tensor å¹¶å­˜å…¥ model_inputs
    model_inputs["positions"] = Tensor.from_numpy(positions.astype(np.int32))
    return model_inputs, prefill
```

**å…³é”®å‘ç°**ï¼š
- MCore ä½¿ç”¨çš„é”®åæ˜¯ **"positions"**ï¼Œä¸æ˜¯ "position_ids"
- MCore ä¼š**è‡ªåŠ¨ç”Ÿæˆ** position_ids
- ä½†å‰ææ˜¯è¦è°ƒç”¨æ­£ç¡®çš„æ¥å£ï¼š`infer_mcore()`

## âœ… æœ€ç»ˆè§£å†³æ–¹æ¡ˆ

### ä¿®æ”¹å†…å®¹

åœ¨ `test_qwen3_mindformers.py` çš„ `test_infer` å‡½æ•°ä¸­ï¼š

```python
# æ£€æµ‹æ¨¡å‹æ¶æ„ç±»å‹
from mindformers.core.context import is_legacy_model
use_legacy = is_legacy_model()

if use_legacy:
    # Legacy æ¨¡å‹ï¼šä½¿ç”¨ infer()
    infer_output, is_finished = model.infer(
        input_ids=input_ids_np,
        valid_length_each_example=valid_length_each_example,
        generation_config=gen_config,
        position_ids=position_ids,  # éœ€è¦æ˜¾å¼ä¼ é€’
        ...
    )
else:
    # MCore æ¨¡å‹ï¼ˆQwen3ï¼‰ï¼šä½¿ç”¨ infer_mcore()
    infer_output, is_finished = model.infer_mcore(
        input_ids=input_ids_np,
        valid_length_each_example=valid_length_each_example,
        generation_config=gen_config,
        block_tables=block_tables,
        slot_mapping=slot_mapping,
        prefill=prefill,
        is_finished=is_finished,
        # ä¸éœ€è¦ä¼ é€’ position_idsï¼ä¼šè‡ªåŠ¨ç”Ÿæˆ
    )
```

## ğŸ“Š ä¸ºä»€ä¹ˆ generate èƒ½æˆåŠŸï¼Ÿ

ä½ å¯èƒ½ä¼šé—®ï¼šä¸ºä»€ä¹ˆ `generate()` æµ‹è¯•æˆåŠŸäº†ï¼Ÿ

**ç­”æ¡ˆ**ï¼š`generate()` å†…éƒ¨ä¼šè‡ªåŠ¨æ£€æµ‹æ¨¡å‹æ¶æ„ï¼

```python
# mindformers/generation/text_generator.py, ç¬¬ 863-1098 è¡Œ
def generate(self, ...):
    use_legacy = is_legacy_model()  # è‡ªåŠ¨æ£€æµ‹
    
    # åœ¨ç”Ÿæˆå¾ªç¯ä¸­
    if use_legacy:
        infer_output, is_finished = self.infer(...)  # Legacy è·¯å¾„
    else:
        infer_output, is_finished = self.infer_mcore(...)  # MCore è·¯å¾„
```

æ‰€ä»¥ `generate()` ä¼šè‡ªåŠ¨é€‰æ‹©æ­£ç¡®çš„æ¥å£ï¼Œè€Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨ `infer()` æ—¶èµ°äº†é”™è¯¯çš„è·¯å¾„ï¼

## ğŸ“ å­¦åˆ°çš„ç»éªŒ

### 1. ç†è§£æ¡†æ¶æ¶æ„æ¼”è¿›

MindFormers æœ‰ä¸¤ä»£æ¶æ„ï¼š
- **Legacy**ï¼šæ—§ç‰ˆæ¶æ„ï¼Œå•æœºæˆ–ç®€å•å¹¶è¡Œ
- **MCore (Parallel Core)**ï¼šæ–°æ¶æ„ï¼Œæ”¯æŒé«˜çº§å¹¶è¡Œç­–ç•¥

### 2. é«˜å±‚ API vs ä½å±‚ API

| API | çº§åˆ« | è‡ªåŠ¨å¤„ç† | çµæ´»æ€§ | ä½¿ç”¨åœºæ™¯ |
|-----|------|---------|-------|---------|
| `generate()` | é«˜å±‚ | âœ… æ¶æ„æ£€æµ‹<br>âœ… å‚æ•°å‡†å¤‡ | ä½ | ç”Ÿäº§ç¯å¢ƒ |
| `infer()` / `infer_mcore()` | ä½å±‚ | âŒ éœ€è¦æ‰‹åŠ¨é€‰æ‹© | é«˜ | è°ƒè¯•/æ§åˆ¶ |

### 3. è°ƒè¯•ç­–ç•¥

1. **æŸ¥çœ‹é”™è¯¯å †æ ˆ**ï¼šç¡®å®šä»£ç æ‰§è¡Œè·¯å¾„
2. **åˆ†æè°ƒç”¨é“¾**ï¼šç†è§£æ•°æ®æµå‘
3. **å¯¹æ¯”æºç **ï¼šæ‰¾å‡ºå…³é”®å·®å¼‚
4. **å‚è€ƒæˆåŠŸæ¡ˆä¾‹**ï¼šçœ‹ `generate()` å¦‚ä½•å·¥ä½œ

## ğŸš€ æµ‹è¯•å‘½ä»¤

ç°åœ¨å¯ä»¥ç›´æ¥è¿è¡Œï¼š

```bash
python test_qwen3_mindformers.py \
    --config models/predict_qwen3.yaml \
    --test_mode both \
    --prompt "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚" \
    --max_new_tokens 50
```

## ğŸ“‹ ä¿®æ”¹æ–‡ä»¶æ¸…å•

1. **test_qwen3_mindformers.py** âœ…
   - æ·»åŠ æ¨¡å‹æ¶æ„æ£€æµ‹
   - æ ¹æ®æ¶æ„é€‰æ‹©æ­£ç¡®çš„ infer æ¥å£
   - MCore æ¨¡å‹è°ƒç”¨ `infer_mcore()`

2. **QUICK_FIX_GUIDE.md** âœ…
   - æ·»åŠ æ¶æ„æ£€æµ‹è¯´æ˜
   - æ›´æ–°é¢„æœŸè¾“å‡º
   - æ·»åŠ  Legacy vs MCore å¯¹æ¯”è¡¨

3. **FINAL_FIX_SUMMARY.md** âœ…ï¼ˆæœ¬æ–‡ä»¶ï¼‰
   - å®Œæ•´çš„é—®é¢˜åˆ†æ
   - æ ¹æœ¬åŸå› è§£é‡Š
   - è§£å†³æ–¹æ¡ˆè¯´æ˜

## ğŸ‰ æ€»ç»“

ç»è¿‡ä¸‰è½®è°ƒè¯•ï¼Œç»ˆäºæ‰¾åˆ°äº†æ ¹æœ¬åŸå› ï¼š

1. **ç¬¬ä¸€è½®**ï¼šæµ‹è¯•é¡ºåºé—®é¢˜ â†’ è°ƒæ•´ä¸º infer â†’ generate âœ…
2. **ç¬¬äºŒè½®**ï¼šç¼ºå°‘ position_ids â†’ å°è¯•ä¼ é€’ position_ids âŒ (æ— æ•ˆ)
3. **ç¬¬ä¸‰è½®**ï¼šæ¥å£é€‰æ‹©é”™è¯¯ â†’ ä½¿ç”¨ infer_mcore() âœ… (æ­£ç¡®)

**å…³é”®æ•™è®­**ï¼šæ·±å…¥ç†è§£æ¡†æ¶æ¶æ„ï¼Œä½¿ç”¨æ­£ç¡®çš„ APIï¼

---

å¸Œæœ›è¿™ä¸ªæ€»ç»“å¯¹ä½ æœ‰å¸®åŠ©ï¼ç°åœ¨è¿è¡Œæµ‹è¯•åº”è¯¥å®Œå…¨æ­£å¸¸äº†ã€‚ğŸš€

